{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "CLIP for visual features extraction, BERT for text features extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load baseline train/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8500 train samples\n",
      "500 test samples\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_json(\"hateful_memes/train.jsonl\", lines=True)\n",
    "test_df = pd.read_json(\"hateful_memes/dev_seen.jsonl\", lines=True)\n",
    "\n",
    "print(len(train_df), \"train samples\")\n",
    "print(len(test_df), \"test samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load train/test data augmented with blip2 captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8500 train samples\n",
      "500 test samples\n"
     ]
    }
   ],
   "source": [
    "train_df_blip2 = pd.read_pickle(\"blip2_augmented_fhm_train.pkl\")\n",
    "test_df_blip2 = pd.read_pickle(\"blip2_augmented_fhm_test.pkl\")\n",
    "\n",
    "# The captions are in list form (e.g. [\"caption\"]), so convert to just string\n",
    "train_df_blip2[\"blip2_caption\"] = train_df_blip2[\"blip2_caption\"].apply(lambda x: x[0])\n",
    "test_df_blip2[\"blip2_caption\"] = test_df_blip2[\"blip2_caption\"].apply(lambda x: x[0])\n",
    "\n",
    "print(len(train_df_blip2), \"train samples\")\n",
    "print(len(test_df_blip2), \"test samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_hate</th>\n",
       "      <th>img</th>\n",
       "      <th>text</th>\n",
       "      <th>blip2_caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[not_hateful]</td>\n",
       "      <td>img/42953.png</td>\n",
       "      <td>its their character not their color that matters</td>\n",
       "      <td>a man with a bald head and a caption of a man ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[not_hateful]</td>\n",
       "      <td>img/23058.png</td>\n",
       "      <td>don't be afraid to love again everyone is not ...</td>\n",
       "      <td>a man and woman are standing close together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[not_hateful]</td>\n",
       "      <td>img/13894.png</td>\n",
       "      <td>putting bows on your pet</td>\n",
       "      <td>a cat with a red bow on its neck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[not_hateful]</td>\n",
       "      <td>img/37408.png</td>\n",
       "      <td>i love everything and everybody! except for sq...</td>\n",
       "      <td>a dog is sitting on the ground and a picture o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[not_hateful]</td>\n",
       "      <td>img/82403.png</td>\n",
       "      <td>everybody loves chocolate chip cookies, even h...</td>\n",
       "      <td>a man in a suit and tie is holding a chocolate...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       gold_hate            img  \\\n",
       "0  [not_hateful]  img/42953.png   \n",
       "1  [not_hateful]  img/23058.png   \n",
       "2  [not_hateful]  img/13894.png   \n",
       "3  [not_hateful]  img/37408.png   \n",
       "4  [not_hateful]  img/82403.png   \n",
       "\n",
       "                                                text  \\\n",
       "0   its their character not their color that matters   \n",
       "1  don't be afraid to love again everyone is not ...   \n",
       "2                           putting bows on your pet   \n",
       "3  i love everything and everybody! except for sq...   \n",
       "4  everybody loves chocolate chip cookies, even h...   \n",
       "\n",
       "                                       blip2_caption  \n",
       "0  a man with a bald head and a caption of a man ...  \n",
       "1        a man and woman are standing close together  \n",
       "2                   a cat with a red bow on its neck  \n",
       "3  a dog is sitting on the ground and a picture o...  \n",
       "4  a man in a suit and tie is holding a chocolate...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_blip2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42953</td>\n",
       "      <td>img/42953.png</td>\n",
       "      <td>0</td>\n",
       "      <td>its their character not their color that matters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23058</td>\n",
       "      <td>img/23058.png</td>\n",
       "      <td>0</td>\n",
       "      <td>don't be afraid to love again everyone is not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13894</td>\n",
       "      <td>img/13894.png</td>\n",
       "      <td>0</td>\n",
       "      <td>putting bows on your pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37408</td>\n",
       "      <td>img/37408.png</td>\n",
       "      <td>0</td>\n",
       "      <td>i love everything and everybody! except for sq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82403</td>\n",
       "      <td>img/82403.png</td>\n",
       "      <td>0</td>\n",
       "      <td>everybody loves chocolate chip cookies, even h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id            img  label  \\\n",
       "0  42953  img/42953.png      0   \n",
       "1  23058  img/23058.png      0   \n",
       "2  13894  img/13894.png      0   \n",
       "3  37408  img/37408.png      0   \n",
       "4  82403  img/82403.png      0   \n",
       "\n",
       "                                                text  \n",
       "0   its their character not their color that matters  \n",
       "1  don't be afraid to love again everyone is not ...  \n",
       "2                           putting bows on your pet  \n",
       "3  i love everything and everybody! except for sq...  \n",
       "4  everybody loves chocolate chip cookies, even h...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLIP\n",
    "Using the ViT-B/32 model. Extracted features are saved in a new column in the pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying image feature extraction to every row image. Both train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_img_feature(row):\n",
    "    hateful_memes_dir = \"hateful_memes\"\n",
    "    img = Image.open(hateful_memes_dir + \"/\" + row[\"img\"])\n",
    "    img = preprocess(img).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        image_features = model.encode_image(img)\n",
    "\n",
    "    return image_features.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['img_features'] = train_df.apply(extract_img_feature, axis=1)\n",
    "test_df['img_features'] = test_df.apply(extract_img_feature, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same images, so can just copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_blip2['img_features'] = train_df['img_features']\n",
    "test_df_blip2['img_features'] = test_df['img_features']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT\n",
    "Using the base BERT model to encode the text. This is also saved in a new column in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_text(row):\n",
    "    inputs = tokenizer(row[\"text\"], return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "    attention_mask = inputs['attention_mask'].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "    last_hidden_states = outputs.last_hidden_state\n",
    "    embedding = last_hidden_states[:, 0, :].cpu().numpy()\n",
    "    \n",
    "    return embedding\n",
    "\n",
    "def encode_caption(row):\n",
    "    inputs = tokenizer(row[\"blip2_caption\"], return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "    attention_mask = inputs['attention_mask'].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "    last_hidden_states = outputs.last_hidden_state\n",
    "    embedding = last_hidden_states[:, 0, :].cpu().numpy()\n",
    "    \n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['text_features'] = train_df.apply(encode_text, axis=1)\n",
    "test_df['text_features'] = test_df.apply(encode_text, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text features are also same, can just copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_blip2['text_features'] = train_df['text_features']\n",
    "test_df_blip2['text_features'] = test_df['text_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_blip2['blip_features'] = train_df_blip2.apply(encode_caption, axis=1)\n",
    "test_df_blip2['blip_features'] = test_df_blip2.apply(encode_caption, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle\n",
    "The dataframes are eventually pickled to a file for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_pickle(\"fhm_clip_bert_features_train.pkl\")\n",
    "test_df.to_pickle(\"fhm_clip_bert_features_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_blip2.to_pickle(\"fhm_clip_bert_features_blip2_train.pkl\")\n",
    "test_df_blip2.to_pickle(\"fhm_clip_bert_features_blip2_test.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
